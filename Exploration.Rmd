---
title: "Does Prenatal Care Improve Child Health?"
subtitle: "W203 - Statistics For Data Science Lab 4"
author: "Felipe Campos, Josh Wilson and Stanimir Vichev"
date: "4/26/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(car)
library(lmtest)
library(sandwich)
library(ggplot2)
library(stargazer)
library(sandwich)
library(lmtest)
library(leaps)
```

# Introduction

For much of human existence, child birth has been an extraordinarily risky endeavor, often ending with the death of either the mother or baby. With the advent of modern medicine and technology, much of the world has seen a significant reduction in the rate of child berth related deaths and of child deaths. While this is something to applaud, there is still much work to be done. Child development after berth is a crucial period during which many of the neurological and motor skills necessary for a full and healthy life ossify. Anything parents can do to increase the healthiness of the baby in this period could have substantial effects on a baby's health. One avenue that might have a positive impact is during the actual pregnancy. Some women engage in prenatal activities that may be risky and others engage in prenatal activities that might be salubrious. In this study, We seek to determine whether prenatal care has an effect on the health of a newborn.


# Data Assessment

```{r load}
load("bwght_w203.RData")
```

## Data Quality Assessment

```{r}
apply(data, 2, function(x) mean(is.na(x)))
```

The data quality assessment shows that only a few variables have larger percentages of missing data (~6%). The fact that the average number of drinks per night or cigarrettes per week variables have the most missing data could indicate that many mothers who did consume alcohol or cigarettes during their pregnacy refused to answer, which could lead to nonresponse bias. 

```{r} 
length(which(is.na(data["cigs"]) == T & is.na(data[,"drink"]) == T ))
```

Also, there are a lot of people (107) that didn't answer both the smoking and drinking questions. 

```{r}
missing_data <- is.na(data)
which(apply(missing_data,1,mean)>.2)
```
The above check shows the few data points, which have the highest percentage of missing data per row. We can consider removing these data points if any of the missing data gets in the way of our hypothesis testing.

The omaps and fmaps variables have the exact same number of missing data. If this happens on the same observation, then we might have hospital bias, as some hospitals might not do these measurements. 

Finally, we notice that there are several data points in which mothers began prenatal care at the zeroeth month and yet also made 0 visits. We cannot be sure whether this is an accurate data point representing mothers who sought no prenatal care or whether this is an error and these points need to be excluded. To be safe, we will exclude them.

```{r}
data_orig <- data
errors = which(data[,"monpre"] == 0 & data[,"npvis"] == 0 )
data <-data[-errors,]
```

## Exploratory Analysis of each variable

Our exploratory analysis begins with an assessment of three possible dependent variables. Measurement of an infant's health immediately after birth can come in various forms and the dataset we have includes three different measurements: birthweight, the one-minute APGAR score, and the five-minute APGAR score. After we determine our preferred dependent variable, we will delve into the various independent variables available to measure level of prenatal care administered to mothers. Of course, it is reasonable to expect that during 9 months of gestation other variables besides those related to prenatal care may have an impact on the health of the infant, so we examine these variables and consider whether we need to control for them in isolating the effect of prenatal care.

We now look at the prospective dependent variables we might use to measure infant health. 

**Birth Weight**

```{r bwght}
ggplot(data = data, aes(x = data$bwght)) + geom_histogram(bins = 50, fill="dodgerblue1", colour = "black") +
  ggtitle('Birthweight of Infants') + xlab("Baby Birthweight (in grams)") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The birth weight variable is fairly normally distributed, even though it has a small negative skew. While it doesn't require any transformation, we could take log base 10 of birth weight, which when interpreted in a regression model would become a percent change in weight. This is a very good candidate for our dependent variable, because it is a continuous quantitative feature that is generally considered a good indicator of overall baby health. Moreover, there is no subjectivity to this measure: an infant is weighed and that measurement is recorded, whereas in the APGAR score - which we discuss below - the doctor makes diagnostic assessments that are subject to human error. If the data were collected from certain hospitals, then the APGAR scores could be correlated with each other by including multiple assessments from the same doctor (other correlations would also creep in).

**One- and Five- Minute APGAR Scores**

```{r omaps}
omaps_summary <- summary(data$omaps)
fmaps_summary <- summary(data$fmaps)
combined_summary <- rbind(omaps_summary, fmaps_summary)
rownames(combined_summary) <- c("1-Min APGAR Scores", "5-Min APGAR Scores")
knitr::kable(combined_summary, caption = "APGAR Scores Statistics")
```

The one- and five- minute APGAR scores are a quick and easy scale that doctors can use to judge how healthy an infant looks one minute and five minutes after it is born. It is generally used as a measure of the short-term health of the baby, helping doctors decide whether a baby will need immediate medical assistance. It is calculated by the doctor judging a baby on a scale of 0 to 2 across five different metrics (activity, pulse, grimace, appearance, respiration).

Therefore, this means that the APGAR scores are essentially an ordinal variable, since we cannot determine whether the difference between a 10 and 9 is the same as the distance between a 2 and a 1 but we do know that 10 is better than 9. As we can see from the summary table of both APGAR scores, most of the scores are an 8 or above, which means that we don't have a lot of lower results to help us determine the effect of prenatal care in all cases. For these reasons and the reasons discussed above, we do not believe the APGAR scores are a good measure of infant health, and we therefore opt to use birthweight as our dependent variable in the models below.

## Exploratory Analysis of Independent Variables

**Length of Prenatal Care**

```{r monpre}
ggplot(data = data, aes(x = data$monpre)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5) +
  ggtitle('Month Prenatal Care Started') + xlab("Month") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5)) + scale_x_continuous(breaks = c(0:10))
```

The monpre variable signifies the month of pregnancy at which prenatal care started, and is one of the key variables we expect to help us predict infant health. It ranges from zero to nine, which means there is probably some rounding as prenatal care is unlikely to begin at conception. This would make sense as we are dealing with a discrete variable. The histogram of monpre shows that the data has a heavy positive skew. There are large peaks at one and two, meaning that most women start prenatal care towards the middle of or end of the first trimester. Unfortunately, we do not know what type of prenatal care this variable maps to. When is prenatal care considered to have begun and what counts? We assume that prenatal care has begun with the first visit to a doctor or midwife, although it may truly begin with a phone call.

**Number of Prenatal Visits** 

```{r npvis}
ggplot(data = data, aes(x = data$npvis)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5, bins = 30) +
  ggtitle('Number of Prenatal Care Visits') + xlab("Prenatal Care Visits") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The number of prenatal visits is another key metric we expect will have an effect on infant health. It has a strong positive skew, and we can see a massive peak at 12 visits. This could be because mothers with insurance that took part in this study were eligible for a certain number of prenatal visits (possibly 12) for free, leading to a lot of women making exactly that many visits. The question of who pays for these visits could have a confounding effect, because it is more likely for mothers to make more visits if they are free and they would probably make less visits if they aren't. 
Plotting the bivariate relationship between number of visits and the month at which prenatal care started (see below), we can see the possible outliers in the top right portion of the plot. These  mothers had around 30 visits, even though they started their prenatal care in the 8th month. It could be the case that these mothers were admitted into hospital for a long period for a specific health problem, but we should check if these  points have an influence on the regression line of our models. 

```{r}
ggplot(data = data, aes(x =data$monpre , y = data$npvis)) + geom_point() + geom_smooth(method = "loess") + geom_jitter(width = 0.2, height = 0.1) + ggtitle("Month Prenatal Care Began vs. Total Number of Prenatal Visits") + xlab("Month Prenatal Care Began") + ylab("Total Number of Prenatal Visits") + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5)) + scale_x_continuous(breaks = c(0:9))
```


**Age Variables**

```{r mage}
mage_summary <- summary(data$mage)
fage_summary <- summary(data$fage)
agesummary <- rbind(mage_summary,fage_summary)
rownames(agesummary) <- c("Mother Age","Father Age")
knitr::kable(agesummary, caption = "Mother and Father Age Statistics")
```

The father and mother age variables both have fairly normal distributions around the 30-year mark, with the father age variable having a slight positive skew. This should mean that this dataset is fairly representative from an age perspective. 

**Education variables**

```{r meduc}
ggplot(data = data, aes(x = meduc)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5, bins = 30) + ggtitle("Education Level of Mothers") + xlab("Education (Years)") + ylab("Count") + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The mother and father education variables both show signs of graduation effect at the 12 (high school) and 16 (college) mark. Therefore, we can bucket this variable into high school, college, and further education (see Variable Transformation below).

```{r}
cor(data[complete.cases(data$feduc) & complete.cases(data$meduc),]$feduc, 
    data[complete.cases(data$feduc) & complete.cases(data$meduc),]$meduc)
```

Additionally, there is about 60% correlation between the education of the mother and father of each baby in the dataset, which aligns with the general notion that people marry others of the same education level.

**Cigarettes**

```{r cigs}

ggplot(data = data, aes(x = cigs)) + 
  geom_histogram(fill="dodgerblue1", colour = "black", boundary = -0.5) +
  ggtitle("Daily Cigarette Consumption During Pregnancy") + 
  ylab("Count") + 
  xlab("Cigarettes Per Day") + theme(axis.text.x = element_text(face = "bold"), 
                                     axis.text.y = element_text(face = "bold"), 
                                     plot.title = element_text(size = 14, face = "bold",
                                                               hjust = 0.5))
```

The cigarettes variable has a peak at zero and a strong positive skew. Only about 14% of the data is of actual smokers, so we could get some skewed results. The distribution is very dispersed, with peaks at the 10, 20, 30, and 40 mark. This shows that people tended to round to these values, perhaps because they didn't know the exact number. This could lead to loss of important detail in the data, but the variable could still be used as an indicator of whether people are heavy, light or non-smokers in general (see variable transformation below).

**Drinking**

In this dataset, there are only about 16 people that actually drank any alcohol during their pregnancy, and they make up only about 1% of the data. While it makes sense that respondents would stop drinking (or at least say they did) during their pregnancy, such a small amount of actual drinkers means this variable will not be helpful in explaining variances in infant health.

**Infant Gender**

```{r}
male <- length(data$male[data$male == 1])
female <- length(data$male[data$male == 0])
gender <- cbind(male,female)
colnames(gender) <- c("Male","Female")
knitr::kable(gender, caption = "Baby Gender Frequency")
```

There are 891 female and 941 male infants in this data set. This might be a useful  variable that might help us control for physiological factors unique to male and female infants.

**Race**

```{r mwhte}
mrace <- cbind(nrow(data[data$mwhte == 1,]), # 1624
              nrow(data[data$mblck == 1,]), # 109
              nrow(data[data$moth == 1,])) # 99
frace <- cbind(nrow(data[data$fwhte == 1,]), # 1630
              nrow(data[data$fblck == 1,]), # 107
              nrow(data[data$foth == 1,])) # 95
colnames(mrace) <- c("White","Black","Other")
colnames(frace) <- c("White","Black","Other")
knitr::kable(mrace, caption = "Mother Race Frequency")
knitr::kable(frace, caption = "Father Race Frequency")
```

This study covers 1620 white, 108 black and 99 women of other races. The results for men is similar. While we don't expect race to have any effect on infant health, it is worth noting that the data is very skewed. 


## Variable transformation

As stated in the prior section, a few transformations would be useful for some of the variables of interest. First of all, we analyze the case of the `cigs` variable, which measures the number of cigarettes smoked per day. As stated previously, this variable shows a distribution with lots of spikes in values multiple of 10, which suggest that maybe the mothers were surveyed and tended to round the number of cigarettes smoked a day either up or down. Therefore, the use of such imprecise numbers could introduce a great amount of error in our model. A transformation to an indicator or categorial variable, then, would be of interest.

From some studies conducted, we could find that the average smoker in the United States tend to smoke somewhere between 10 to 20 cigarettes a day, depending on their state. Therefore, we have segregated smokers into four different categories: non-smoker (zero cigarettes a day), light smoker (more than zero but less or equal to ten cigarettes a day), average smoker (more than 10 and less or equal to 20 cigarettes a day) and heavy smoker (more than 20 cigarettes a day). This segregation would allow us to control the outcome for different levels of smoking in our model, if desired. We also created an indicator variable if the mother is a smoker or not, being considered a smoker if she smoked one or more cigarettes a day.

```{r}
data$nonsmoker <- ifelse(data$cigs == 0 & !is.na(data$cigs), 1, 0)
data$smoker <- ifelse(data$cigs > 0 & !is.na(data$cigs), 1, 0)
data$lightsmoker <- ifelse(data$cigs > 0 & data$cigs <= 10 & !is.na(data$cigs), 1, 0)
data$occsmoker <- ifelse(data$cigs > 10 & data$cigs <= 20 & !is.na(data$cigs), 1, 0)
data$heavysmoker <- ifelse(data$cigs > 20 & !is.na(data$cigs), 1, 0)
```

By analyzing the transformed variables, we get the following frequencies:

```{r}
smoking <- cbind(nrow(data[data$nonsmoker == 1,]),
                 nrow(data[data$lightsmoker == 1,]),
                 nrow(data[data$occsmoker == 1,]),
                 nrow(data[data$heavysmoker == 1,]))
colnames(smoking) <- c("Non-Smoker", "Light Smoker", "Average Smoker", "Heavy Smoker")
rownames(smoking) <- c("Frequency")
knitr::kable(smoking, caption = "Smoking Mother Categories Frquency")
smoking2 <- cbind(nrow(data[data$nonsmoker == 1,]),
                 nrow(data[data$smoker == 1,]))
colnames(smoking2) <- c("Non-Smoker", "Smoker")
rownames(smoking2) <- c("Frequency")
knitr::kable(smoking2, caption = "Number of Smoking and Non-Smoking Mothers")
```

Due to very small numbers of average and heavy smokers in the sample, it could perhaps not be representative to our model and those categories would not be of so much value. Therefore, for our models, we decided to use the indicator variable `smoker` instead.

We then proceed to transforming the education variables for mothers and fathers. As analyzed before, the distribution of this variable also suffer from notable spikes due to milestones in a person's educational life, such as completing high school or college. Therefore, it makes sense to use a categorical variable for education to measure each person's level of education, thus avoiding the possible introduction of error from the measurement of years of education. We then separate people based on the categories based on their years of education.

```{r}
data$mheduc <- ifelse(data$meduc < 12 & !is.na(data$meduc), 1, 0)
data$fheduc <- ifelse(data$feduc < 12 & !is.na(data$feduc), 1, 0)
data$mceduc <- ifelse(data$meduc >= 12 & data$meduc <16  & !is.na(data$meduc), 1, 0)
data$fceduc <- ifelse(data$feduc >= 12 & data$feduc <16  & !is.na(data$feduc), 1, 0)
data$mfureduc <- ifelse(data$meduc >= 16  & !is.na(data$meduc), 1, 0)
data$ffureduc <- ifelse(data$feduc >= 16  & !is.na(data$feduc), 1, 0)
```

We then get the following frequencies for each educational category:

```{r}
meduc <- cbind(nrow(data[data$mheduc == 1,]),
                 nrow(data[data$mceduc == 1,]),
                 nrow(data[data$mfureduc == 1,]))
colnames(meduc) <- c("High School", "College", "Further Education")
rownames(meduc) <- c("Frequency")
knitr::kable(meduc, caption = "Mother Education Categories Frquency")
feduc <- cbind(nrow(data[data$fheduc == 1,]),
                 nrow(data[data$fceduc == 1,]),
                 nrow(data[data$ffureduc == 1,]))
colnames(feduc) <- c("High School", "College", "Further Education")
rownames(feduc) <- c("Frequency")
knitr::kable(feduc, caption = "Father Education Categories Frquency")
```


# Model Development

## Initial Model

Our first model uses birth weight as the dependent variable and regresses it on what we consider the key independent variables: number of prenatal visits and month at which visits started.

```{r model1}
model1 = lm(bwght ~ monpre + npvis, data = data)
```

This model will now be analyzed in further detail for all Classical Linear Model assumptions and its interpretation.

## CLM Assumptions For Initial Model

**Linearity of Parameters**

Looking at the residuals vs. fitted graph below, we don't see any systematic bias or non-linear shapes in the data that might indicate that the underlying population is not linear with respect to the parameters.

```{r}
plot(model1, which = 1)
```

**Random Sample**

The information provided in this data set does not allow us to judge the sampling procedure of this study and determine whether it is random or not. While we can see a large group of respondents that didn't answer both the cigarettes and drinks question, this isn't enough evidence to assume lack of randomness. 

Similarly, the high median values for the one-minute and five-minute APGAR scores might make us question the random sampling assumption, but such distribution might actually be representative of a healthy population in a developed country like the USA. Finally, there is the potential for correlation between patients if the sampling was done at a hospital level, but we don't have enough information to assess this and therefore the sample will be considered random.

Verifying the Residuals vs Leverage plot below, we can see that although we have a few data points with great leverage, there are none exerting great influence in the fitted model.

```{r}
plot(model1, which = 5)
```

**Multicollinearity**

We used a correlation matrix to look at the correlation between the variables we wanted to use in our models, which won't be reproduced here due to space constraints, and we didn't find any two that were perfectly correlated.

**Zero-Conditional Mean**

Instead of a horizontal line at 0, our residuals vs. fitted graph, already displayed above, shows a negative trending line in our starts above zero and ends below it. The deviations from zero happen towards the fringes of the fitted values, suggesting that high leverage points may be affecting the fit of the model or that not enough data was collected for these values. Within the most dense portion of the data, we do see that the zero mean conditional is satisfied. Overall, we believe this assumption is satisfied.

**Homoskedasticity**

Looking at the residuals vs. fitted graph displayed previously and the scale-location plot below, we can see that the middle of the data looks fairly homoskedastic, while variance (and the number of data points) seems to decrease as we move to the left and right. This could be evidence of potential heteroskedasticity, but we don't know if that is genuine or just an artifact of the small number of data points in the extreme. Therefore, we choose to err on the side of caution and use heteroskedasticity-robust standard errors in our calculation.

```{r}
plot(model1, which = 3)
```

**Normality**

Looking at the Q-Q plot below, we can see that the normality assumption is violated on the left side of the graph, around -2 standard deviations, where we have a heavy left tail. However, as we have a fairly large dataset, we can rely on asymptotics for this fairly normal dataset. 

```{r}
plot(model1, which = 2)
```

## Initial Model Interpretation

```{r}
coeftest(model1, vcov = vcovHC)
```

Using the robust standard errors, we can see that the number of prenatal visits variable is statistically significant, while the month that prenatal care began is not. The built-in F-test also shows us that our choice of variables does have some result. 

An interpretation of this model could be that, everything else held constant, for every additional prenatal visit the baby's birthweight would increase by approximately 18 grams. While this is statistically significant, it does not seem to be very practically significant.

## Second Model

For the second model, we add some variables that should help us control for some other factors, such as the mother's age, smoking habits, her educational background, and the baby's gender.  Controlling for the baby's gender is important because there might be physiological factors different for baby boys and baby girls.  Controlling for the mother's smoking  and age allows us to capture the effect this might have on the health of the baby. Finally, controlling for the mother's education could also be important, because more educated people might make more healthy choices during pregnancy and might be more aware of what to avoid for the baby's health. 

```{r model2}
model2 = lm(bwght ~ monpre + npvis + smoker + male + mage + mheduc + mceduc, data = data)
plot(model2, which = 1)
```

In terms of CLM assumptions, we see that the residuals vs fitted graph above displays a much more horizontal line, meaning that the zero conditional mean is even more satisfied. At the same time, the band of residuals seems to be more consistent from left to right, showing better signs of homoskedasticity.


## Second Model Interpretation

```{r}
coeftest(model2, vcov = vcovHC)
linearHypothesis(model2, c("mage = 0", "mheduc= 0", "mceduc = 0"), vcov = vcovHC)
```

We can see that whether the mother smokes or not and whether the baby is male or not has a statistical significance when predicting birth weight. They also seem to have some practical significance, as a male baby will be 73 grams heavier than a female baby, ceteris paribus. Similarly, mothers that smoke will have babies that are 205 grams (a significant amount) lighter than if the mothers didn't smoke. The direction of these coefficients are in line with what we would generally assume.

It is also interesting to note that is this model, the month of the first prenatal visit became statistically significant, indicating that for each month closer to the date the baby is born there is a 24 gram increase in birthweight, which would go in the opposite direction of what we would think.

The mother's age and levels of education aren't statistically significant on their own, and an F-test confirms that they are not jointly statistically significant as well. 

## Third Model

In our final model, we use all the above variables, but we also add variables related to the father's age and education. We don't expect these to have an effect on the baby's birthweight, although our model might be less reliable because of the higher correlation between the father and mother age parameters. 

```{r model3}
model3 = lm(bwght ~ monpre + npvis + smoker + male + mage + mheduc + mceduc + fheduc + fceduc + fage, data = data)
plot(model3, which = 1)
```

The plots don't display any visible changes to the assumptions. However, we can compare the variance inflation factor between the second and third models.

```{r}
vif2 <- c(vif(model2),NA,NA,NA)
vif3 <- vif(model3)
names(vif2) <- names(vif3)
vifs23 <- rbind(vif2,vif3)
rownames(vifs23) <- c("(2)","(3)")
knitr::kable(vifs23, caption = "Variance Inflation Factor Comparison Between Models")
```

The VIF for the mage, mheduc, and mceduc variables has increased substantially, which could indicate that this model violates the multicollinearity assumption.  

## Third Model Interpretation

```{r}
coeftest(model3, vcov = vcovHC)
linearHypothesis(model3, c("fheduc = 0", "fceduc = 0", "fage = 0", "mage = 0", "mheduc= 0", "mceduc = 0"), vcov = vcovHC)
```

The newly added variables don't seem to be individually statistically significant. Additionally, an F-test shows that they aren't jointly statistically significant as well. Looking at their coefficients, we can see that they seem to point in illogical directions. 

## Model Comparison

```{r, results  = 'asis'}
model1stat <- coeftest(model1, vcov = vcovHC)
model2stat <- coeftest(model2, vcov = vcovHC)
model3stat <- coeftest(model3, vcov = vcovHC)
stargazer(model1, model2, model3, type = "latex", report = "vcstp*", header = FALSE,
          coef = list(model1stat[,"Estimate"],model2stat[,"Estimate"],model3stat[,"Estimate"]),
          se = list(model1stat[,"Std. Error"],model2stat[,"Std. Error"],model3stat[,"Std. Error"]),
          t.auto = TRUE, p.auto = TRUE,
          title = "Prenatal Care Influence In Birthweight",
          keep.stat = c("rsq", "aic", "n", "adj.rsq"),
          single.row = TRUE,
          omit.table.layout = "n",
          add.lines = list(c("AIC", 
                             round(AIC(model1),digits=3), 
                             round(AIC(model2), digits=3), 
                             round(AIC(model3), digits=3))))
```

TO DO: here we can compare practical/statistical significance, std errors and AIC values of the three models.

# Causality discussion

The first step in assessing whether a causal argument can be made begins with understanding the data generating process. Ideally, we would want a randomized controlled study; this would give us the power to isolate the effects of causes. We know from the information provided that this data come from National Center for Health Statistics, and a cursory search suggests that the CDC would implement a highly rigorous randomized design. However, there is no evidence to suggest some sort of control mechanism was in place. Since we are dealing with maternal behavior during pregnancy, it is unreasonable and possibly unethical to deny some mothers the ability to adopt behaviors that may be beneficial for their fetus. From this reasoning, it would appear that the data we have come from an observational study.

The mere fact that the data come from an observational study does not destroy the ability to detect the effects of causes. However, we would need to know more about the data collection process. How many mothers dropped out of the study? Are there imbalances on some of the variables that we measured? For example, it might be that the proportion of highly educated women is higher than it is in the population. The lack of information on the data collection procedures casts grave doubt on whether we can interpret the results of our regression analysis causally.

As a check on causality, we would wish to see data collected on many variables that we would intuitively believe to be important. For example, whether a mother carries the baby to term or delivers prematurely could have a large effect on baby health; whether there are complications during the pregnancy that affect the growth of the fetus may also play a role; and lastly, general health of the mother may also figure into the equation. When we do not have these variables they get put into the error term, which we are not able to control. This fact together with the lack of information on randomization is a death knell for any causal interpretation.

Model Selection Using Leaps
```{r}
str(data)
regsubsets_out <- regsubsets(bwght ~ mage + meduc + monpre + npvis + fage + feduc + cigs + drink + male + mwhte + mblck + fwhte + fblck + npvissq, data = data, nbest = 1, nvmax = NULL, force.in = NULL, force.out = NULL, method = "exhaustive")
summary_out <- summary(regsubsets_out)
as.data.frame(summary_out$outmat)


plot(regsubsets_out, scale = "adjr2", main = "Adjusted R^2")
```


# Conclusion


