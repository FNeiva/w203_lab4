---
title: "Does Prenatal Care Improve Child Health?"
subtitle: "W203 - Statistics For Data Science Lab 4"
author: "Felipe Campos, Josh Wilson and Stanimir Vichev"
date: "4/26/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(car)
library(lmtest)
library(sandwich)
library(ggplot2)
library(stargazer)
library(sandwich)
library(lmtest)
library(leaps)
```

# Introduction

For much of human existence, child birth has been an extraordinarily risky endeavor, often ending with the death of either the mother or baby. With the advent of modern medicine and technology, much of the world has seen a significant reduction in the rate of child berth related deaths and of child deaths. While this is something to applaud, there is still much work to be done. Child development after berth is a crucial period during which many of the neurological and motor skills necessary for a full and healthy life ossify. Anything parents can do to increase the healthiness of the baby in this period could have substantial effects on a baby's health. One avenue that might have a positive impact is during the actual pregnancy. Some women engage in prenatal activities that may be risky and others engage in prenatal activities that might be salubrious. In this study, We seek to determine whether prenatal care has an effect on the health of a newborn.


# Data Load

We include this snippet of code so that the audience may know the data set with which we are conducting these analyses.

```{r load}
load("bwght_w203.RData")
```

## Data Quality Assessment

The first question asked of any data set is always 

```{r}
apply(data, 2, function(x) mean(is.na(x)))
```

The data quality assessment shows that only a few variables have larger percentages of missing data (~6%). The fact that the average number of drinks per night or cigarrettes per week variables have the most missing data could indicate that many mothers who did consume alcohol or cigarettes during their pregnacy refused to answer, which could lead to nonresponse bias. 

```{r} 
length(which(is.na(data["cigs"]) == T & is.na(data[,"drink"]) == T ))
```

Also, there are a lot of people (107) that didn't answer both the smoking and drinking questions. 

```{r}
missing_data <- is.na(data)
which(apply(missing_data,1,mean)>.2)
```
The above check shows the few data points, which have the highest percentage of missing data per row. We can consider removing these data points if any of the missing data gets in the way of our hypothesis testing.

The omaps and fmaps variables have the exact same number of missing data. If this happens on the same observation, then we might have hospital bias, as some hospitals might not do these measurements. 

Finally, we notice that there are several data points in which mothers began prenatal care at the zeroeth month and yet also made 0 visits. We cannot be sure whether this is an accurate data point representing mothers who sought no prenatal care or whether this is an error and these points need to be excluded. To be safe, we will exclude them.

```{r}
data_orig <- data
errors <- which(data[,"monpre"] == 0 & data[,"npvis"] == 0 )
data <-data[-errors,]
```

## Exploratory Analysis of each variable

Our exploratory analysis begins with an assessment of three possible dependent variables. Measurement of an infant's health immediately after birth can come in various forms and the dataset we have includes three different measurements: birthweight, the one-minute APGAR score, and the five-minute APGAR score. After we determine our preferred dependent variable, we will delve into the various independent variables available to measure level of prenatal care administered to mothers. Of course, it is reasonable to expect that during 9 months of gestation other variables besides those related to prenatal care may have an impact on the health of the infant, so we examine these variables and consider whether we need to control for them in isolating the effect of prenatal care.

We now look at the prospective dependent variables we might use to measure infant health. 

**Birth Weight**

```{r bwght, include = F}
ggplot(data = data, aes(x = data$bwght)) + geom_histogram(bins = 50, fill="dodgerblue1", colour = "black") +
  ggtitle('Birthweight of Infants') + xlab("Baby Birthweight (in grams)") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The birth weight variable is fairly normally distributed, even though it has a small negative skew. While it doesn't require any transformation, we could take log base 10 of birth weight, which when interpreted in a regression model would become a percent change in weight. This is a very good candidate for our dependent variable, because it is a continuous quantitative feature that is generally considered a good indicator of overall baby health. Moreover, there is no subjectivity to this measure: an infant is weighed and that measurement is recorded, whereas in the APGAR score - which we discuss below - the doctor makes diagnostic assessments that are subject to human error. If the data were collected from certain hospitals, then the APGAR scores could be correlated with each other by including multiple assessments from the same doctor (other correlations would also creep in).

**One- and Five- Minute APGAR Scores**

```{r omaps}
omaps_summary <- summary(data$omaps)
fmaps_summary <- summary(data$fmaps)
combined_summary <- rbind(omaps_summary, fmaps_summary)
rownames(combined_summary) <- c("1-Min APGAR Scores", "5-Min APGAR Scores")
knitr::kable(combined_summary, caption = "APGAR Scores Statistics")
```

The one- and five- minute APGAR scores are a quick and easy scale that doctors can use to judge how healthy an infant looks one minute and five minutes after it is born. It is generally used as a measure of the short-term health of the baby, helping doctors decide whether a baby will need immediate medical assistance. It is calculated by the doctor judging a baby on a scale of 0 to 2 across five different metrics (activity, pulse, grimace, appearance, respiration).

Therefore, this means that the APGAR scores are essentially an ordinal variable, since we cannot determine whether the difference between a 10 and 9 is the same as the distance between a 2 and a 1 but we do know that 10 is better than 9. As we can see from the summary table of both APGAR scores, most of the scores are an 8 or above, which means that we don't have a lot of lower results to help us determine the effect of prenatal care in all cases. For these reasons and the reasons discussed above, we do not believe the APGAR scores are a good measure of infant health, and we therefore opt to use birthweight as our dependent variable in the models below.

## Exploratory Analysis of Independent Variables

**Length of Prenatal Care**

```{r monpre, include = F}
ggplot(data = data, aes(x = data$monpre)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5) +
  ggtitle('Month Prenatal Care Started') + xlab("Month") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5)) + scale_x_continuous(breaks = c(0:10))
```

The monpre variable signifies the month of pregnancy at which prenatal care started, and is one of the key variables we expect to help us predict infant health. It ranges from zero to nine, which means there is probably some rounding as prenatal care is unlikely to begin at conception. This would make sense as we are dealing with a discrete variable. The histogram of monpre shows that the data has a heavy positive skew. There are large peaks at one and two, meaning that most women start prenatal care towards the middle of or end of the first trimester. Unfortunately, we do not know what type of prenatal care this variable maps to. When is prenatal care considered to have begun and what counts? We assume that prenatal care has begun with the first visit to a doctor or midwife, although it may truly begin with a phone call.

**Number of Prenatal Visits** 

```{r npvis, include = F}
ggplot(data = data, aes(x = data$npvis)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5, bins = 30) +
  ggtitle('Number of Prenatal Care Visits') + xlab("Prenatal Care Visits") +
  ylab('Count') + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The number of prenatal visits is another key metric we expect will have an effect on infant health. It has a strong positive skew, and we can see a massive peak at 12 visits. This could be because mothers with insurance that took part in this study were eligible for a certain number of prenatal visits (possibly 12) for free, leading to a lot of women making exactly that many visits. The question of who pays for these visits could have a confounding effect, because it is more likely for mothers to make more visits if they are free and they would probably make less visits if they aren't. 
Plotting the bivariate relationship between number of visits and the month at which prenatal care started (see below), we can see the possible outliers in the top right portion of the plot. These  mothers had around 30 visits, even though they started their prenatal care in the 8th month. It could be the case that these mothers were admitted into hospital for a long period for a specific health problem, but we should check if these  points have an influence on the regression line of our models. 

```{r, include = F}
ggplot(data = data, aes(x =data$monpre , y = data$npvis)) + geom_point() + geom_smooth(method = "loess") + geom_jitter(width = 0.2, height = 0.1) + ggtitle("Month Prenatal Care Began vs. Total Number of Prenatal Visits") + xlab("Month Prenatal Care Began") + ylab("Total Number of Prenatal Visits") + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5)) + scale_x_continuous(breaks = c(0:9))
```


**Age Variables**

```{r mage}
mage_summary <- summary(data$mage)
fage_summary <- summary(data$fage)
agesummary <- rbind(mage_summary,fage_summary)
rownames(agesummary) <- c("Mother Age","Father Age")
knitr::kable(agesummary, caption = "Mother and Father Age Statistics")
```

The father and mother age variables both have fairly normal distributions around the 30-year mark, with the father age variable having a slight positive skew. This should mean that this dataset is fairly representative from an age perspective. 

**Education variables**

```{r meduc}
ggplot(data = data, aes(x = meduc)) + geom_histogram(binwidth = 1, fill="dodgerblue1", colour = "black", boundary = -0.5, bins = 30) + ggtitle("Education Level of Mothers") + xlab("Education (Years)") + ylab("Count") + theme(axis.text.x = element_text(face = "bold"), axis.text.y = element_text(face = "bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

The mother and father education variables both show signs of graduation effect at the 12 (high school) and 16 (college) mark. Therefore, we can bucket this variable into high school, college, and further education (see Variable Transformation below).

```{r}
cor(data[complete.cases(data$feduc) & complete.cases(data$meduc),]$feduc, 
    data[complete.cases(data$feduc) & complete.cases(data$meduc),]$meduc)
```

Additionally, there is about 60% correlation between the education of the mother and father of each baby in the dataset, which aligns with the general notion that people marry others of the same education level.

**Cigarettes**

```{r cigs, include = F}

ggplot(data = data, aes(x = cigs)) + 
  geom_histogram(fill="dodgerblue1", colour = "black", boundary = -0.5) +
  ggtitle("Daily Cigarette Consumption During Pregnancy") + 
  ylab("Count") + 
  xlab("Cigarettes Per Day") + theme(axis.text.x = element_text(face = "bold"), 
                                     axis.text.y = element_text(face = "bold"), 
                                     plot.title = element_text(size = 14, face = "bold",
                                                               hjust = 0.5))
```

The cigarettes variable has a peak at zero and a strong positive skew. Only about 14% of the data is of actual smokers, so we could get some skewed results. The distribution is very dispersed, with peaks at the 10, 20, 30, and 40 mark. This shows that people tended to round to these values, perhaps because they didn't know the exact number. This could lead to loss of important detail in the data, but the variable could still be used as an indicator of whether people are heavy, light or non-smokers in general (see variable transformation below).

**Drinking**

In this dataset, there are only about 16 people that actually drank any alcohol during their pregnancy, and they make up only about 1% of the data. While it makes sense that respondents would stop drinking (or at least say they did) during their pregnancy, such a small amount of actual drinkers means this variable will not be helpful in explaining variances in infant health.

**Infant Gender**

```{r}
male <- length(data$male[data$male == 1])
female <- length(data$male[data$male == 0])
gender <- cbind(male,female)
colnames(gender) <- c("Male","Female")
knitr::kable(gender, caption = "Baby Gender Frequency")
```

There are 891 female and 941 male infants in this data set. This might be a useful  variable that might help us control for physiological factors unique to male and female infants.

**Race**

```{r mwhte}
mrace <- cbind(nrow(data[data$mwhte == 1,]), # 1624
              nrow(data[data$mblck == 1,]), # 109
              nrow(data[data$moth == 1,])) # 99
frace <- cbind(nrow(data[data$fwhte == 1,]), # 1630
              nrow(data[data$fblck == 1,]), # 107
              nrow(data[data$foth == 1,])) # 95
colnames(mrace) <- c("White","Black","Other")
colnames(frace) <- c("White","Black","Other")
knitr::kable(mrace, caption = "Mother Race Frequency")
knitr::kable(frace, caption = "Father Race Frequency")
```

This study covers 1620 white, 108 black and 99 women of other races. The results for men is similar. While we don't expect race to have any effect on infant health, it is worth noting that the data is very skewed. 


## Variable transformation

As stated in the prior section, a few transformations would be useful for some of the variables of interest. First of all, we analyze the case of the `cigs` variable, which measures the number of cigarettes smoked per day. As stated previously, this variable shows a distribution with lots of spikes in values multiple of 10, which suggest that maybe the mothers were surveyed and tended to round the number of cigarettes smoked a day either up or down. Therefore, the use of such imprecise numbers could introduce a great amount of error in our model. A transformation to an indicator or categorial variable, then, would be of interest.

From some studies conducted, we could find that the average smoker in the United States tend to smoke somewhere between 10 to 20 cigarettes a day, depending on their state. Therefore, we have segregated smokers into four different categories: non-smoker (zero cigarettes a day), light smoker (more than zero but less or equal to ten cigarettes a day), average smoker (more than 10 and less or equal to 20 cigarettes a day) and heavy smoker (more than 20 cigarettes a day). This segregation would allow us to control the outcome for different levels of smoking in our model, if desired. We also created an indicator variable if the mother is a smoker or not, being considered a smoker if she smoked one or more cigarettes a day.

```{r}
data$nonsmoker <- ifelse(data$cigs == 0 & !is.na(data$cigs), 1, 0)
data$smoker <- ifelse(data$cigs > 0 & !is.na(data$cigs), 1, 0)
data$lightsmoker <- ifelse(data$cigs > 0 & data$cigs <= 10 & !is.na(data$cigs), 1, 0)
data$occsmoker <- ifelse(data$cigs > 10 & data$cigs <= 20 & !is.na(data$cigs), 1, 0)
data$heavysmoker <- ifelse(data$cigs > 20 & !is.na(data$cigs), 1, 0)
```

By analyzing the transformed variables, we get the following frequencies:

```{r}
smoking <- cbind(nrow(data[data$nonsmoker == 1,]),
                 nrow(data[data$lightsmoker == 1,]),
                 nrow(data[data$occsmoker == 1,]),
                 nrow(data[data$heavysmoker == 1,]))
colnames(smoking) <- c("Non-Smoker", "Light Smoker", "Average Smoker", "Heavy Smoker")
rownames(smoking) <- c("Frequency")
knitr::kable(smoking, caption = "Smoking Mother Categories Frquency")
smoking2 <- cbind(nrow(data[data$nonsmoker == 1,]),
                 nrow(data[data$smoker == 1,]))
colnames(smoking2) <- c("Non-Smoker", "Smoker")
rownames(smoking2) <- c("Frequency")
knitr::kable(smoking2, caption = "Number of Smoking and Non-Smoking Mothers")
```

Due to very small numbers of average and heavy smokers in the sample, it could perhaps not be representative to our model and those categories would not be of so much value. Therefore, for our models, we decided to use the indicator variable `smoker` instead.

We then proceed to transforming the education variables for mothers and fathers. As analyzed before, the distribution of this variable also suffers from notable spikes due to milestones in a person's educational life, such as completing high school or college. Therefore, it makes sense to use a categorical variable for education to measure each person's level of education, thus avoiding the possible introduction of error from the measurement of years of education. We then separate people into categories based on their years of education.

```{r}
data$mheduc <- ifelse(data$meduc < 12 & !is.na(data$meduc), 1, 0)
data$fheduc <- ifelse(data$feduc < 12 & !is.na(data$feduc), 1, 0)
data$mceduc <- ifelse(data$meduc >= 12 & data$meduc <16  & !is.na(data$meduc), 1, 0)
data$fceduc <- ifelse(data$feduc >= 12 & data$feduc <16  & !is.na(data$feduc), 1, 0)
data$mfureduc <- ifelse(data$meduc >= 16  & !is.na(data$meduc), 1, 0)
data$ffureduc <- ifelse(data$feduc >= 16  & !is.na(data$feduc), 1, 0)
```

Doing so, we get the following frequencies for each educational category:

```{r}
meduc <- cbind(nrow(data[data$mheduc == 1,]),
                 nrow(data[data$mceduc == 1,]),
                 nrow(data[data$mfureduc == 1,]))
colnames(meduc) <- c("High School", "College", "Further Education")
rownames(meduc) <- c("Frequency")
knitr::kable(meduc, caption = "Mother Education Categories Frquency")
feduc <- cbind(nrow(data[data$fheduc == 1,]),
                 nrow(data[data$fceduc == 1,]),
                 nrow(data[data$ffureduc == 1,]))
colnames(feduc) <- c("High School", "College", "Further Education")
rownames(feduc) <- c("Frequency")
knitr::kable(feduc, caption = "Father Education Categories Frquency")
```


# Model Development

## Initial Model

Our first model uses birth weight as the dependent variable and regresses it on what we consider the key independent variables related to prenatal care: number of prenatal visits and month at which visits started.

```{r model1}
model1 <- lm(bwght ~ monpre + npvis, data = data)
```

Before we interpret the model results, we will examine each of the CLM assumptions to see whether they are met or not. Understanding the residuals and the model fit will be an instrumental backdrop against which we can interpret the statistical significance of coefficients and model fit. Our analysis of the CLM assumption follows.

## CLM Assumptions For Initial Model

**Linearity of Parameters**

The linearity of parameters is an essential assumption which, if broken, essentially nullifies any interpretation of the model. We can assess whether this assumption is broken by looking for systematic bias in the residuals vs. fitted plot. By inspection of this plot below, we don't see any systematic bias or non-linear shapes in the data that might indicate that the underlying population is not linear with respect to the parameters. Moreover, when we examined the bivariate relationships between the dependent and independent variables (separately) above, we did not see any evidence to suggest a nonlinear relationship. Therefore, the linearity of parameters assumption is met by this model.

```{r}
plot(model1, which = 1)
```

**Random Sample**

The information provided in this data set only allows us to make inferences about the sampling procedure of this study and determine whether it is random or not. That is, we can examine the data to see if there is any apparent bias, such as overrepresentation of white mothers vs. other mothers. When we look at the table for race, we see that White, which we are assuming to include both non-hispanic white + hispanic white, represents nearly 89% of our sample. As compared to the national average, our sample does appear to have a larger proportion of white women (not necessarily mothers) and to be underrepresented in black mothers. Whether this departure represents a violation of the random sample assumption is difficult to assess, because we would expect some differences in our sample as compared to the national average.

Other small issues we detected may also suggest bias in the sample: a large group of respondents did not answer both the cigarettes and drinks question. This is evidence of a different kind of bias that does not necessarily mean the technique to select the sample was not random. However, it does suggest that in the data collection process, there might have been forces at play that produce a data set that is not random for one reason or another.

In a similar vein, the high median values for the one-minute and five-minute APGAR scores cause us to question how the random sampling was implemented. It may be the case that such a distribution might actually be representative of a healthy population in a developed country like the USA. Or, the randomization might have occurred at the hospital level, and the healthiness of the infants might be due to some other lurking variables.

Even though we have some evidence that our sample has bias, we cannot definitively say that the random sample assumption is not met. Instead, we believe that this evidence runs counter to any causal claims, but that it does not invalidate the model.

**Multicollinearity**

We initially used a correlation matrix to look at the correlation between the variables we wanted to use in our models (not reproduced here due to space constraints) and we did not find much evidence of high correlation. Specifically, for the initial model, we also included the variance inflation factor calculations to check this assumptions. Both variance inflation calculations are close to 1, meaning we do not have cause to be concerned that the multicollinearity assumption is not met.

```{r}
vif(model1)
```


**Zero-Conditional Mean**

We can determine whether the zero-conditional mean assumption is met by examining the residuals vs. fitted plot, which we have included above. Ideally, we would like to see a horizontal line at 0, but our plot shows a negative trending line from the right end of the mass. The deviations from zero happen towards the fringes of the fitted values, suggesting that there might be high leverage points affecting the fit of the model or that the scarcity of data may also be playing a role. Within the most dense portion of the data, we do see that the zero mean conditional is satisfied. Overall, we believe this assumption is largely satisfied, although we have concern for the right end of the graph.

**Homoskedasticity**


Again, we can assess whether the homoskedasticity assumption is met by inspecting the residuals vs. fitted plot. Evidence of fanning in the residuals would suggest that we have heteroskedasticity. From the plot, we do not see much evidence of fanning, but we note that towards each end of the plot, where the data becomes more scarce, the variance seems to decrease. This could be evidence of potential heteroskedasticity, but we don't know if that is genuine or just an artifact of the small number of data points in the extreme. Moreover, the scale-location plot below does not appear to have any particular shape. Therefore, we have choosen to err on the side of caution and use heteroskedasticity-robust standard errors in our subsequent calculations.

```{r}
plot(model1, which = 3)
```

**Normality**

In order to assess the normality assumption of CLM, we examine the Q_Q plot, where we can detect whether there are large departures from the theoretical normal distribution of errors. From this plot, we can see that the normality assumption does appear to be violated on the left side of the graph. Around -2 standard deviations, we appear to have a heavy left tail that departs from the theoretical distribution. Generally, this deviation from normality would require a transformation of the predictor and/or the explanatory variables. However, as we have a fairly large dataset and the departure was resistant to nonlinear transformations that we tested, we do not believe that this deviation will have a significant impact on interpreting the results. 

```{r}
plot(model1, which = 2)
```

## Initial Model Interpretation

```{r}
coeftest(model1, vcov = vcovHC)
```


Our first model only includes the month prenatal care began and the number of visits. We have applied robust errors because of the potential heteroskedasticity we detected in the diagnostic plots above. This model is relatively simple but this belies what is actually going on. The effect size for both months prior and the number of visits are the same, it is only the standard error which is drastically different between the two that causes the differences in statistical interpretation: the number of visits is statistically different from zero while the month prenatal care begins is not. The straightforward interpretation would say the only thing that matters is the number of visits and not when you start the visits. That is, two women who start at different months but have the same number of visits will, on average, produce babies whose weight, and thereby health, is roughly the same. The effect size for the number of visits suggests that a mother who does 12 visits should have a baby whose birthweight is approximately 180 grams (0.4 lbs) more than a mother who does 2 visits. This is not an insignificant difference, but how this difference maps to the health of an infant is difficult to determine. Moreover, a single unit difference in npvis, ceteris paribus, is associated with just over .6 ounces increase in the weight of an infant. This may have no significant practical interpretation.

## Second Model

For the second model, we add variables that should help us control for some factors that could affect the health of the infant beyond prenatal care, such as the mother's age, smoking habits, a mother's educational background, and the baby's gender.  Controlling for the baby's gender is important because there are likely to be physiological factors that make infant boys heavier than infant girls on average. It is reasonable to believe that infant boys will be larger, and therefore heavier than infant girls, just based on the fact that men are generally larger than women.  We also control for the mother's smoking habits as smoking has been found to have an effect on health of an infant and this type of risky behavior may be indicative of other risky behaviors in which a mother engages. The age of the mother may also have an effect on the health of an infant, if for example, the body's ability to nurture a baby decreases over time. Finally, we control for the mother's education, because more educated people might make more healthy choices during pregnancy and might be more aware of what to avoid during pregnancy. Education might also be indicative of socio-economic status, and therefore pertain to availability of prenatal care.

```{r model2}
model2 = lm(bwght ~ monpre + npvis + smoker + male + mage + mheduc + mceduc, data = data)
plot(model2, which = 1)
```

After investigating all of the diagnostic plots associated with the classical linear model assumptions, we believe there is not much of a change from the diagnostics in the first model. We do happen to see a slight improvement in the flatness of the line in the residuals vs. fitted plot, which we include here. This suggests improvement in meeting the zero conditional mean. For all intents and purposes, this fit may be as good as we can get with regards to completely satisfying the zero-mean conditional assumption. It is tough to visually diagnose small improvements towards homoskedasticity, but we believe the variation of residuals is now marginally more consistent from left to right, showing better signs of homoskedasticity.


## Second Model Interpretation

```{r}
coeftest(model2, vcov = vcovHC)
linearHypothesis(model2, c("mage = 0", "mheduc= 0", "mceduc = 0"), vcov = vcovHC)
```

We can see that whether the mother smokes or not and whether the baby is male or not has a statistical significance when predicting birth weight. They also seem to have some practical significance, as a male baby will be 73 grams heavier than a female baby, ceteris paribus. Similarly, mothers that smoke will have babies that are 205 grams (a significant amount) lighter than mothers that didn't smoke. The direction of these coefficients are in line with what we would generally assume.

It is also interesting to note that, in this model, the month of the first prenatal visit became statistically significant, indicating that for each month closer to the date the baby is born there is a 24 gram increase in birthweight, which would go in the opposite direction of what we would think.

The mother's age and levels of education aren't statistically significant on their own, and an F-test confirms that they are not jointly statistically significant as well. 

## Third Model

In our final model, we use all the above variables, but we also add variables related to the father's age and education. We don't expect these to have an effect on the baby's birthweight, although our model may be less reliable because of the higher correlation between the father and mother age parameters. 

```{r model3}
model3 = lm(bwght ~ monpre + npvis + smoker + male + mage + mheduc + mceduc + fheduc + fceduc + fage, data = data)
plot(model3, which = 1)
```

The plots don't display any visible changes to the assumptions. However, we can compare the variance inflation factor between the second and third models.

```{r}
vif2 <- c(vif(model2),NA,NA,NA)
vif3 <- vif(model3)
names(vif2) <- names(vif3)
vifs23 <- rbind(vif2,vif3)
rownames(vifs23) <- c("(2)","(3)")
knitr::kable(vifs23, caption = "Variance Inflation Factor Comparison Between Models")
```

The VIF for the mage, mheduc, and mceduc variables has increased substantially, which indicates that, even though there is no perfect multicollinearity, the high correlation between those variables could be biasing the model and inflating the variance in our coefficients.

## Third Model Interpretation

```{r}
coeftest(model3, vcov = vcovHC)
linearHypothesis(model3, c("fheduc = 0", "fceduc = 0", "fage = 0", "mage = 0", "mheduc= 0", "mceduc = 0"), vcov = vcovHC)
```

The newly added variables don't seem to be individually statistically significant, with the exception of father age. An F-test shows that they are jointly statistically significant as well, on a significance level of 95%. Looking at their coefficients, we can see that most of them seem to point in illogical directions. 

The fact that apparently a baby's birthweight would increase by approximately 10 grams for each additional year on father's age could be a potential confounding effect, as we would not expect the father age to positively impact a baby's health. Instead, it could be that older fathers have other characteristics such as being more financially stable that could be influencing this. However, we lack the additional variables that would be required to make such statement, like family income, that could be highly influential in the result. 

## Model Comparison

Table 11 displayed below shows a comparison between all three models developed in this report. All standard errors in the table have been calculated using heteroskedastic-robust methods. 

```{r, results  = 'asis', echo=FALSE}
model1stat <- coeftest(model1, vcov = vcovHC)
model2stat <- coeftest(model2, vcov = vcovHC)
model3stat <- coeftest(model3, vcov = vcovHC)
stargazer(model1, model2, model3, type = "latex", report = "vcstp*", header = FALSE,
          coef = list(model1stat[,"Estimate"],model2stat[,"Estimate"],model3stat[,"Estimate"]),
          se = list(model1stat[,"Std. Error"],model2stat[,"Std. Error"],model3stat[,"Std. Error"]),
          t.auto = TRUE, p.auto = TRUE,
          title = "Prenatal Care Influence In Birthweight",
          keep.stat = c("rsq", "aic", "n", "adj.rsq"),
          single.row = TRUE,
          omit.table.layout = "n",
          add.lines = list(c("AIC", 
                             round(AIC(model1),digits=3), 
                             round(AIC(model2), digits=3), 
                             round(AIC(model3), digits=3))))

```

When we add in our control variables in the second model, we clearly witness a great improvement to $R^2$, meaning that a greater part of the variation in our model is now explained by the new variables added. Although this is expected, as $R^2$ always increases when adding new variables, other measurements used that penalize the model for added complexity such as the Adjusted $R^2$ and Akaike Information Criterion, also displayed in table 11, both demonstrate improvement in model fit.

Two of the new variables introduced in the second model have great statistical significance, `smoker` and `male`. Both cases also display practical significance, with the coefficient values indicating that a male baby is likely to be 73 grams heavier when everything else is held constant and that a smoker mother is likely to have a baby 205 grams lighter than a non-smoking mother, ceteris paribus. The addition of new variables also made the initial month for prenatal care statistically significant at a 95% confidence level. This indicates that mothers would be likely to have a baby 24 grams heavier for each month closer to conception when they begin their prenatal care, which goes against our preconceived notion that longer prenatal care would be more likely to result in healthier babies.

For the third model, we added the variables containing age and education for the babys' fathers. By doing this, we note that we have a better Adjusted $R^2$ and Akaike Information Criterion value indicating that this model is a better fit than the previous one and the addition of new variables is worthwhile in explaining the variation in the data. However, we must note that, as explained before, given that the father age and education variables are highly correlated with the mother age and education variables, their addition also increased the Variance Inflation Factor in our regression coefficients. Therefore, the trade-off between better fit and increased variance should be thoroughly analyzed before choosing between one or the other.

By verifying the third model, we can see that all previous significant variables remained significant, except for the month prenatal care began, and that the father age is highly statistically significant. Its coefficient indicates that for each additional year in the father age, holding everything else constant, the baby is likely to present an approximate 9.4 grams increase in weight. While this may seem a small value, a 40-year-old father would probably generate a baby 94 grams heavier than a 30-year-old father. As explained before, it goes against the logic that older fathers would give birth to healthier babies, so this could be a potential confounding effect that we should be aware of that is probably related to family income, which we would expect to be higher for older fathers, or the capability of older fathers to provide for mothers while they are dedicated to their pregnancy.

# Causality discussion

The first step in assessing whether a causal argument can be made begins with understanding the data generating process. Ideally, we would want a randomized controlled study; this would give us the power to isolate the effects of causes. We know from the information provided that this data come from National Center for Health Statistics, and a cursory search suggests that the CDC would implement a highly rigorous randomized design. However, there is no evidence to suggest some sort of control mechanism was in place. Since we are dealing with maternal behavior during pregnancy, it is unreasonable and possibly unethical to deny some mothers the ability to adopt behaviors that may be beneficial for their fetus. From this reasoning, it would appear that the data we have come from an observational study.

The mere fact that the data come from an observational study does not destroy the ability to detect the effects of causes. However, we would need to know more about the data collection process. How many mothers dropped out of the study? Are there imbalances on some of the variables that we measured? For example, it might be that the proportion of highly educated women is higher than it is in the population. The lack of information on the data collection procedures casts grave doubt on whether we can interpret the results of our regression analysis causally.

As a check on causality, we would wish to see data collected on many variables that we would intuitively believe to be important. For example, whether a mother carries the baby to term or delivers prematurely could have a large effect on baby health; whether there are complications during the pregnancy that affect the growth of the fetus may also play a role; and lastly, general health of the mother may also figure into the equation. When we do not have these variables they get put into the error term, which we are not able to control. This fact together with the lack of information on randomization is a death knell for any causal interpretation.

Model Selection Using Leaps
```{r}
str(data)
regsubsets_out <- regsubsets(bwght ~ mage + meduc + monpre + npvis + fage + feduc + cigs + drink + male + mwhte + mblck + fwhte + fblck + npvissq, data = data, nbest = 1, nvmax = NULL, force.in = NULL, force.out = NULL, method = "exhaustive")
summary_out <- summary(regsubsets_out)
as.data.frame(summary_out$outmat)


plot(regsubsets_out, scale = "adjr2", main = "Adjusted R^2")
```


# Conclusion


